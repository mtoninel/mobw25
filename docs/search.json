[
  {
    "objectID": "pages/day1.html",
    "href": "pages/day1.html",
    "title": "Day 1",
    "section": "",
    "text": "Setup RStudio or Posit\nGet familiar with the Posit interface\nLearn about bulk RNA-seq data processing\nDownload the data needed for the workshop"
  },
  {
    "objectID": "pages/day1.html#using-rstudio-or-posit",
    "href": "pages/day1.html#using-rstudio-or-posit",
    "title": "Day 1",
    "section": "Using Rstudio or Posit",
    "text": "Using Rstudio or Posit\nIf RStudio is not installed on your computer, you can create a free account on posit.cloud. Create the account with your credentials and follow the instructions to create a new project. Once done, you should see something like this on your screen:\n\n\n\nThis is your working interface, the bottom right section shows your current file system (on the cloud) which is now pointed to the place where the Rproject you just created lives. The section on the left currently displays your console, where you can type R code interactively."
  },
  {
    "objectID": "pages/day1.html#communicating-with-r",
    "href": "pages/day1.html#communicating-with-r",
    "title": "Day 1",
    "section": "Communicating with R",
    "text": "Communicating with R\nYou should see your cursor on the left-hand side of the screen blinking. That window represents the R console. It can be used to ‚Äútalk‚Äù with R through commands that it can understand!\n\nPrinting Text\nFor example, try typing the following in the console and check what comes out (a.k.a. the output):\n\n# Tell R to print out some words on screen with the \"print\" command\nprint(\"Hello World!\")\n\n[1] \"Hello World!\"\n\n\n\n\nCreating Variables\nOne of the main aspects of any programming language including R is the ability to create variables. You can think of variables as ways to store objects under any given name. Let‚Äôs take the previous example and store the Hello World! character (known as a string) in a variable that we call my_variable. The creation of a variable in R is classically done through the assignment operator <-.\n\n# Let's assign the statement to a variable (nothing happens when running this code)\nmy_variable <- \"Hello World!\"\n\n# Let's display the content of the new variable!\nprint(my_variable)\n\n[1] \"Hello World!\"\n\n\n\nüí° What happened in the top right part of your screen when you ran the code lines above? Check out the ‚Äúenvironment‚Äù section, you should see that my_variable appeared there!\n\n\n\nData Types: Tables\nWithout going too much into the details of all the available objects used to store data in R, one of the most abundantly used is the data.frame. Think of data.frames as the R equivalent of Excel spreadsheets, so a way to store tabular data. As we will see later, pretty much all the data we are going to handle will be in the form of a data.frame or some of its other variations.\n\n# Let's create and display a data frame (a table) with four rows and two columns\ndata.frame(\"Class\"=c(\"a\",\"b\",\"c\",\"d\"), # First column\n            \"Quantity\"=c(1,10,4,6)) # Second column\n\n  Class Quantity\n1     a        1\n2     b       10\n3     c        4\n4     d        6\n\n\nYou have now instructed R to do something for you! We will ask it to do plenty more in the code chunks below!"
  },
  {
    "objectID": "pages/day1.html#creating-a-script",
    "href": "pages/day1.html#creating-a-script",
    "title": "Day 1",
    "section": "Creating a script",
    "text": "Creating a script\nIn the console we can type as many commands as we want and execute them sequentially. Nevertheless, commands typed in the console are lost the moment they are executed and if we want to execute them again we need to type everything back in the console‚Ä¶ this is painful!\nA script is just a normal text file which groups a series of commands that R can execute sequentially, reading the file line-by-line. This is much better because we can then edit the file and save the changes!\nFollow the movie below to create an R script in Posit, the same applies to Rstudio, notice the .R extension at the end of the file name.\n\n\n\nThe new window that appeared on the upper left represents your R script. In here we can write R code which DOES NOT get executed immediately like in the console before.\n\nüí° In order to execute code from the script, highlight the code line you want to execute (or put your cursor line on it) and press ‚åò+Enter on Mac or Ctrl+Enter on Windows."
  },
  {
    "objectID": "pages/day1.html#installing-packages",
    "href": "pages/day1.html#installing-packages",
    "title": "Day 1",
    "section": "Installing packages",
    "text": "Installing packages\nThe analyses that we are going to conduct require specific packages. In R, packages are collections of functions which help us perform standardized workflows. In the code chunk below, we instruct R to install the packages that we will need later on throughout the workshop.\n\nüí° Copy and paste this and the other code chunks from here to your R script to follow.\n\n\n# Install packages from Bioconductor\nif (!require(\"BiocManager\", quietly = TRUE))\n  install.packages(\"BiocManager\")\n\n# Install packages from CRAN\ninstall.packages(\"tidyr\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"googledrive\")\n\n# For differential expression\nBiocManager::install(\"vsn\")\nBiocManager::install(\"edgeR\")\ninstall.packages(\"statmod\")\n\n# For visualizations\ninstall.packages(\"hexbin\")\ninstall.packages(\"pheatmap\")\ninstall.packages(\"RColorBrewer\")\ninstall.packages(\"ggrepel\")\n\n# For conversion between gene IDs\nBiocManager::install(\"org.Hs.eg.db\")\n\n# For downstream analyses\ninstall.packages(\"msigdbr\")\nBiocManager::install(\"fgsea\")\nBiocManager::install(\"clusterProfiler\")\n\n# Remove garbage\ngc()\n\nDuring the installation, you will see many messages being displayed on your R console, don‚Äôt pay too much attention to them unless they are red and specify an error!\nIf you encounter any of these messages during installation, follow this procedure here:\n\n# R asks for package updates, answer \"n\" and type enter\n# Question displayed:\nUpdate all/some/none? [a/s/n]:\n\n# Answer to type:  \nn\n\n# R asks for installation from binary source, answer \"no\" and type enter\n# Question displayed:\nDo you want to install from sources the packages which need compilation? (Yes/no/cancel)\n\n# Answer to type:\nno\n\nHopefully all packages were correctly installed and now we can dive a bit deeper into the theoretical basics of RNA sequencing!"
  },
  {
    "objectID": "pages/day1.html#next-generation-sequencing",
    "href": "pages/day1.html#next-generation-sequencing",
    "title": "Day 1",
    "section": "Next Generation Sequencing",
    "text": "Next Generation Sequencing\nNext Generation Sequencing technologies (Illumina/PacBio) allow experimenters to capture the entire genetic information in a sample in a completely unsupervised manner. The process works with an approach called sequencing-by-synthesis or SBS for short.\n\nüí° Great info can be found at the Illumina Knowledge page\n\nThis means that strands are sequenced by re-building them using the natural complementarity principle of DNA with fluorescently labelled bases which get detected and decoded into sequences. On illumina flow-cells this process happens in clusters, to allow for proper signal amplification and detection, as shown in the movie below."
  },
  {
    "objectID": "pages/day1.html#how-do-we-go-from-mrna-to-sequences",
    "href": "pages/day1.html#how-do-we-go-from-mrna-to-sequences",
    "title": "Day 1",
    "section": "How do we go from mRNA to sequences?",
    "text": "How do we go from mRNA to sequences?\n:::\n\n\n\n::::\nStarting from our precious mRNA molecule that has been isolated from our sample, we transform it into DNA by means of retrotranscription, this process creates what is known as cDNA. cDNA molecules can be very large and due to technical constraints we need to fragment them into smaller pieces. All these pieces are then ligated to a set of sequences known as adapters. As we have seen in the video, adapter sequences are used by the sequencing machine to hibridize cDNA fragments to the flow cell and form sequencing clusters."
  },
  {
    "objectID": "pages/day1.html#raw-sequencing-output",
    "href": "pages/day1.html#raw-sequencing-output",
    "title": "Day 1",
    "section": "Raw Sequencing Output",
    "text": "Raw Sequencing Output\nThe raw output of any sequencing run consists of a series of sequences (called reads). These sequences can have varying length based on the run parameters set on the sequencing platform. Nevertheless, they are made available for humans to read under a standardized file format known as FASTQ. This is the universally accepted format used to encode sequences after sequencing. An example of real FASTQ file with only two reads is provided below.\n\n@Seq1\nAGTCAGTTAAGCTGGTCCGTAGCTCTGAGGCTGACGAGTCGAGCTCGTACG\n+\nBBBEGGGGEGGGFGFGGEFGFGFGGFGGGGGGFGFGFGGGFGFGFGFGFG\n@Seq2\nTGCTAAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGC\n+\nEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n\nFASTQ files are an intermediate file in the analysis and are used to assess quality metrics for any given sequence. The quality of each base call is encoded in the line after the + following the standard Phred score system.\n\nüí° Since we now have an initial metric for each sequence, it is mandatory to conduct some standard quality control evaluation of our sequences to eventually spot technical defects in the sequencing run early on in the analysis."
  },
  {
    "objectID": "pages/day1.html#quality-metrics-inspection",
    "href": "pages/day1.html#quality-metrics-inspection",
    "title": "Day 1",
    "section": "Quality Metrics Inspection",
    "text": "Quality Metrics Inspection\nComputational tools like FastQC aid with the visual inspection of per-sample quality metrics from NGS experiments. Some of the QC metrics of interest to consider include the ones listed below, on the left are optimal metric profiles while on the right are sub-optimal ones:\n\nPer-base Sequence Quality  This uses box plots to highlight the per-base quality along all reads in the sequencing experiment, we can notice a physiological drop in quality towards the end part of the read.\n\n\nPer-sequence Quality Scores  Here we are plotting the distribution of Phred scores across all identified sequences, we can see that the high quality experiment (left) has a peak at higher Phred scores values (34-38).\n\n\nPer-base Sequence Content  Here we check the sequence (read) base content, in a normal scenario we do not expect any dramatic variation across the full length of the read since we should see a quasi-balanced distribution of bases.\n\n\nPer-sequence GC Content  GC-content referes to the degree at which guanosine and cytosine are present within a sequence, in NGS experiments which also include PCR amplification this aspect is crucial to check since GC-poor sequences may be enriched due to their easier amplification bias. In a normal random library we would expect this to have a bell-shaped distribution such as the one on the left.\n\n\nSequence Duplication Levels  This plot shows the degree of sequence duplication levels. In a normal library (left) we expect to have low levels of duplication which can be a positive indicator of high sequencing coverage.\n\n\nAdapter Content  In NGS experiments we use adapters to create a library. Sometimes these can get sequenced accidentally and end up being part of a read. This phenomenon can be spotted here and corrected later using a computational approach called adapter trimming, visible in next section‚Äôs figure."
  },
  {
    "objectID": "pages/day1.html#read-alignment",
    "href": "pages/day1.html#read-alignment",
    "title": "Day 1",
    "section": "Read Alignment",
    "text": "Read Alignment\nOnce we are satisfied with the quality of our pool of sequences, we need to map them back to the transcripts to which they belonged originally when we produced cDNA molecules from RNA. This process of mapping is needed to understand from which genes were transcripts generated and therefore is an essential and very important step of data processing!\n\n\nAlignment of trimmed reads to a reference genome or transcriptome.\n\n\nBut what is a reference genome really?\nWhen we perform an RNA-seq experiment, we need to understand where the millions of reads that we get come from in the genome, in other words, which genes (by being transcribed) contribute to what degree to the amount of signal that we get in each experiment! Since every mRNA (hence cDNA) is different among individuals, we can use a general genome which is manually built and onto which we can place our reads to check for matches and mismatches.\n\nüí° The Human Genome Project for example released the very first assembled reference genome in 2003, using sequencing data coming from at least 10 different individuals and containing more than 3 billion bases! Currently, the most used ‚Äúbuild‚Äù of the human genome is the one called GRCh37, released in 2013.\n\nTools like STAR and BWA-MEM are designed to achieve great speed and accuracy for the computationally expensive task of read alignment.\nThe results of the alignment procedure is a different set of files in SAM (Standard Alignment Map) format which get compressed into their binary representation, BAM files. These are usually one for each analyzed sample and encode the position of all the identified reads along the genome as well as alignment quality metrics for QC, which can be carried out with tools like MultiQC.\n\nüí° All of these pre-processing steps, which are computationally expensive, are usually integrated in command-line pipelines which connect inputs and outputs of these difference procedures in a streamlined manner. An example is the RNA-seq pipeline provided by the nf-core community."
  },
  {
    "objectID": "pages/day1.html#counting-transcripts",
    "href": "pages/day1.html#counting-transcripts",
    "title": "Day 1",
    "section": "Counting Transcripts",
    "text": "Counting Transcripts\nAfter sequences have been aligned to their respective place on the genome, it is time to actually count how many times a given sequence is found on any given gene (or transcripts, or exons or others..), this will actually be our gene expression measurement!\n\n\n\nThere are many ways to achieve this task but among the most used is the featureCounts tool. In the end, for every sample, we will end up with a number for each gene (or transcripts), these are called gene (transcript) counts.\nThese are usually summarized in a table, called gene expression table, where each sample is a column and each row a different gene. We will now load one and take a closer look, this will be our starting point in the hands-on analysis of bulk RNA-seq data.\n\nüí° What is the difference between a gene and a transcript?"
  },
  {
    "objectID": "pages/day1.html#what-data-are-we-going-to-use-what-is-our-question",
    "href": "pages/day1.html#what-data-are-we-going-to-use-what-is-our-question",
    "title": "Day 1",
    "section": "What data are we going to use? What is our question?",
    "text": "What data are we going to use? What is our question?\nWe will load a table of data from this study on tumor-infiltrating CD8+ T-cells. The original data supporting the findings of the study has been deposited on the Gene Expression Omnibus (GEO) data portal under accession number GSE120575. This is the place where all studies publish the processed sequencing data from their analysis in order for other researchers to download it and reproduce their findings or test their own hypotheses.\n\n\n\nBriefly, the authors collected bulk RNA-seq data from different subpopulations of transgenic CD8+ T cells including ones known as exhausted which are particularly relevant in the context of cancer immunotherapy. These cells are in fact consistently exposed to antigens in the tumor microenvironment and become dysfunctional, unable to fight cancer cells which are therefore free to keep expanding. Understanding and preventing the process of T cell exhaustion poses and interesting and relevant challenge in the field of immunotherapies for a variety of cancer types."
  },
  {
    "objectID": "pages/day1.html#loading-the-data",
    "href": "pages/day1.html#loading-the-data",
    "title": "Day 1",
    "section": "Loading The Data",
    "text": "Loading The Data\nWe have already downloaded the data and inserted it in a Google Drive folder organizing it as follows:\n\nraw_counts.csv: the gene by sample matrix containing the number of times each gene is detected in each sample (our gene expression values)\nsamples_info.csv: the table containing samples information, known as metadata, which tells us about the biological meaning of each sample\n\nOpen the folder through your Google Drive (this step is important), check the presence of the files in the browser and then only AFTER having done this, run the code below. After having opened the Google Drive folder, follow the code chunk below where we are going to load the data and create two new variables in our R session, one for each table.\n\nüö® NOTE: After you run the code below, look into your R console and check if you are prompted to insert your Google account information. Do so and then follow the instructions to connect to your Google account in order to download the data from the shared MOBW2025 folder!\n\n\n# Load installed packages with the \"library()\" function\nlibrary(\"dplyr\")\nlibrary(\"googledrive\")\n\n# Load files\nfiles <- drive_ls(path=\"MOBW2025\")\n\n# File paths with URL\ncounts <- files[files$name == \"raw_counts.csv\",] %>% drive_read_string() %>% read.csv(text = .) %>% as.data.frame()\nrownames(counts) <- counts$X\ncounts$X <- NULL\n\nsamples <- files[files$name == \"samples_info.csv\",] %>% drive_read_string() %>% read.csv(text = .) %>% as.data.frame()\nrownames(samples) <- samples$X \nsamples <- samples[,c(\"Donor\",\"SampleGroup\",\"sex\")]\n\nWe can now explore the data that we have just loaded in the current R session to familiarize with it.\n\n# Check out the counts\nhead(counts, 10)\n\n\n\n\n\n \n  \n      \n    BSSE_QGF_204446 \n    BSSE_QGF_204447 \n    BSSE_QGF_204448 \n    BSSE_QGF_204449 \n    BSSE_QGF_204450 \n    BSSE_QGF_204451 \n    BSSE_QGF_204452 \n    BSSE_QGF_204453 \n    BSSE_QGF_204458 \n    BSSE_QGF_204459 \n    BSSE_QGF_204460 \n    BSSE_QGF_204461 \n    BSSE_QGF_204462 \n    BSSE_QGF_204463 \n    BSSE_QGF_204464 \n    BSSE_QGF_204465 \n  \n \n\n  \n    ENSG00000228572 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000182378 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000226179 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000281849 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000280767 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000185960 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    LRG_710 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000237531 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000198223 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    ENSG00000265658 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n\n\n\n\n\nWe can then check the shape of our counts table (i.e.¬†how many different transcripts we are detecting and how many different samples?)\n\n# How many rows and columns does our count table have?\ndim(counts)\n\n[1] 62854    16\n\n\nWe can see that our table contains count information for 62854 genes and 16 samples.\n\nüí° In R, these table object are called data.frames, tibbles are just like them but with some improved functionalities provided by the tidyverse library.\n\nWe can also inspect the metadata from the samples which is stored in the samples variable we created above."
  },
  {
    "objectID": "pages/day1.html#exploring-_meta_data",
    "href": "pages/day1.html#exploring-_meta_data",
    "title": "Day 1",
    "section": "Exploring _meta_data",
    "text": "Exploring _meta_data\nMetadata refers to that class of accessory data to the main experimental readout. In the case of this published dataset, the main data refers to the actual gene expression table with the associated counts measurement for each sample. Each sample then has associated information used to further describe it (e.g.¬†type of cells, patient ID, treatment status, experimental batch‚Ä¶), as we have previously seen, this information is instrumental to bioinformaticians to avoid pitfalls in the analysis. In the case of our data, this information is contained in the samples table. We can use R‚Äôs functionality to explore it and visualize it in order to get an idea about the dataset!\n\n# What does the table look like?\nsamples\n\n\n\n\n\n \n  \n      \n    Donor \n    SampleGroup \n    sex \n  \n \n\n  \n    BSSE_QGF_204446 \n    HD276 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204447 \n    HD276 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204448 \n    HD276 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204449 \n    HD276 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204450 \n    HD280 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204451 \n    HD280 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204452 \n    HD280 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204453 \n    HD280 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204458 \n    HD286 \n    Trest \n    Male \n  \n  \n    BSSE_QGF_204459 \n    HD286 \n    Ttumor \n    Male \n  \n  \n    BSSE_QGF_204460 \n    HD286 \n    Teff \n    Male \n  \n  \n    BSSE_QGF_204461 \n    HD286 \n    Tex \n    Male \n  \n  \n    BSSE_QGF_204462 \n    HD287 \n    Trest \n    Female \n  \n  \n    BSSE_QGF_204463 \n    HD287 \n    Ttumor \n    Female \n  \n  \n    BSSE_QGF_204464 \n    HD287 \n    Teff \n    Female \n  \n  \n    BSSE_QGF_204465 \n    HD287 \n    Tex \n    Female \n  \n\n\n\n\n\n\n# What is the shape of this samples table?\ndim(samples)\n\n[1] 16  3\n\n\nIn this case, this samples table has as many rows (16) as there are samples (which in turn is equal to the number of columns in the counts table), with columns containing different types of information related to each of the samples in the analysis.\n\nMaking graphs and figures in R\nWe can take advantage of the way R handles tabular data to easily plot information and get a visual sense of the dataset. Exploring data in this way is very important, it allows us to detect flaws and weird effects in the data early on, so to avoid any misinterpretation which can greatly impact downstream analysis. For example, taking our samples table, we can ask whether covariates are balanced in the data or some categories are more/less represented than others.\nFor example, let‚Äôs say we want to understand"
  },
  {
    "objectID": "pages/day1.html#savingloading-files",
    "href": "pages/day1.html#savingloading-files",
    "title": "Day 1",
    "section": "Saving/Loading Files",
    "text": "Saving/Loading Files\nLet‚Äôs save this object with samples information in a file on this cloud session, this might be needed later if we end up in some trouble with the R session! This is a file format where columns are separated by commas. You might be familiar with this format if you have worked quite a bit in Excel. In R, we can save tabular data with the write.table() function specifying the location (the file name) we want. This is useful in the case our R session dies or we decide to interrupt it. In this case we will not have to run the whole analysis from the beginning and we can just source the file and load it!\n\nwrite.table(samples, \"samples_table.csv\", sep = \",\", quote = FALSE)\n\nWe can load the object back into the current session by using the following code line:\n\nsamples <- read.table(\"samples_table.csv\", sep = \",\")\n\n\nüí° We will also repeat this procedure with the results of the differential expression analysis in order to avoid repeating work we have already done in case of any trouble!\n\nNow that we have our objects correctly loaded, we can dive into the actual RNA-seq analysis."
  },
  {
    "objectID": "pages/preface.html",
    "href": "pages/preface.html",
    "title": "Preface",
    "section": "",
    "text": "Let‚Äôs look at what ChatGPT outputs when asked the question: ‚ÄúWhat do you think we mean when we say bioinformatics?‚Äù\n\nWhen we say ‚Äúbioinformatics,‚Äù we‚Äôre typically referring to the use of computer science, statistics, and data analysis techniques to understand complex biological data. This often involves analyzing genetic sequences (like DNA or RNA), protein structures, or other molecular biology data to make sense of biological systems, identify patterns, and answer questions related to health, disease, evolution, and more. It‚Äôs about bridging biology with technology to unlock insights from vast amounts of biological data.\n\nBut should we really trust it?\nThis course is aimed at giving you a sense of the possibilities and challenges that come with analyzing high-throughput data so that you can get a feeling for what your answer to that question might be!"
  },
  {
    "objectID": "pages/preface.html#but-why-are-we-talking-about-high-throughput-data",
    "href": "pages/preface.html#but-why-are-we-talking-about-high-throughput-data",
    "title": "Preface",
    "section": "But why are we talking about high throughput data? ü§åüèº",
    "text": "But why are we talking about high throughput data? ü§åüèº\nAs we will see, biological phenomena are extremely complex and hard to make sense of! Just think about the sheer size of the information (how much?) contained in our genome in the form of words composed by just 4 letters and the majority of them don‚Äôt even mean anything! ü§Ø\nLater we will dive into the world of Next Generation Sequencing technologies (NGS) and how they have revolutionized the way we can collect information about the molecules around which life encodes and transfers its information, DNA, RNA and proteins.\n\n\n\nGiven the scale, size and complexity (hence high-throughput) of the data generated by these technologies, human power is not enough to get them processed in a reasonable amount of time‚Ä¶ that‚Äôs where dumb computers come in the picture!"
  },
  {
    "objectID": "pages/preface.html#do-i-need-to-know-how-to-program-computers-to-be-a-bioinformatician",
    "href": "pages/preface.html#do-i-need-to-know-how-to-program-computers-to-be-a-bioinformatician",
    "title": "Preface",
    "section": "Do I need to know how to program computers to be a bioinformatician? üôÉ",
    "text": "Do I need to know how to program computers to be a bioinformatician? üôÉ\nIn short‚Ä¶ YES! But don‚Äôt be intimated by this, we will walk through the computer code in the workshop together, trying to understand it by functionality instead of blindly learning to type some letters on a screen. In particular, bioinformatics has historically revolved around the use of computer terminals (or command-line, CLI), using a terminal basically feels like looking inside the void soul of your computer, a spot of complete darkness, just like you imagine it.\n\n‚ò†Ô∏è If you dare, you can look into the void by typing ‚åò+Space and typing ‚ÄúTerminal‚Äù on Mac or Win+R -> type ‚Äúcmd‚Äù -> press Enter on Windows!\n\nMost data-intensive operations in bioinformatics are handled by specialized ‚Äútools‚Äù (computer programs) that work in this environment, where we need to tell explicitly the computer what to do instead of pushing flashy buttons on the screen, something a bit different than what we are normally used to. This is because your computer‚Äôs Operating System is designed to make its use an actually enjoyable experience for you, but deep down everything ends in the void.\nIn this workshop we are not going to look at the computer‚Äôs terminal archaic way of communicating, we are instead going to instruct our computer on what we want to do by using a more modern and comprehensible language known as R."
  },
  {
    "objectID": "pages/preface.html#what-is-r",
    "href": "pages/preface.html#what-is-r",
    "title": "Preface",
    "section": "What is R? ü§ñ",
    "text": "What is R? ü§ñ\nR is a programming language, what this means is that some people originally created it as a way for humans to write code that can be understood by a computer to perform simple or complex operations! Easy!\nThe main objectives of R as a language are to facilitate their users in performing tasks related to statistics and data analysis, including data visualization and representation.\n\nüí° Have you ever heard of programming languages? Do you know any? Have you had any experience with R?"
  },
  {
    "objectID": "pages/index.html",
    "href": "pages/index.html",
    "title": "Introduction",
    "section": "",
    "text": "The course will give an overview on how to conceptually approach bioinformatics. During the three days of the course we will dive into a bulk RNA-seq experiment and carry out the main steps of a standard data analysis pipeline."
  },
  {
    "objectID": "pages/index.html#day-1",
    "href": "pages/index.html#day-1",
    "title": "Introduction",
    "section": "Day 1 ü§ì",
    "text": "Day 1 ü§ì\n\nSetup RStudio or Posit\nGet familiar with the Posit interface\nLearn about bulk RNA-seq data processing\nDownload the data needed for the workshop"
  },
  {
    "objectID": "pages/index.html#day-2",
    "href": "pages/index.html#day-2",
    "title": "Introduction",
    "section": "Day 2 üßëüèº‚Äçüíª",
    "text": "Day 2 üßëüèº‚Äçüíª\n\nLearn about data normalization\nLearn about the edgeR package\nExplore different normalization methods\nNormalize the data with functions provided by the edgeR package\nPerform diagnostic and exploratory analysis on the data"
  },
  {
    "objectID": "pages/index.html#day-3",
    "href": "pages/index.html#day-3",
    "title": "Introduction",
    "section": "Day 3 üßû‚Äç‚ôÇÔ∏è",
    "text": "Day 3 üßû‚Äç‚ôÇÔ∏è\n\nLearn about the theory behind differential expression analysis\nPerform differential expression analysis using edgeR\nVisualize the results\nPerform further downstream analysis on interesting gene groups"
  },
  {
    "objectID": "pages/index.html#how-to-reach-us",
    "href": "pages/index.html#how-to-reach-us",
    "title": "Introduction",
    "section": "How To Reach Us",
    "text": "How To Reach Us\n\nAnna Beneggi (anna.beneggi@ifom.eu)\nMattia Toninelli (mattia.toninelli@ifom.eu)\n\n\n\n\nFeel free to drop us an e-mail if you have any curiosity or question!"
  },
  {
    "objectID": "pages/preface.html#do-i-need-to-know-how-to-program-computers",
    "href": "pages/preface.html#do-i-need-to-know-how-to-program-computers",
    "title": "Preface",
    "section": "Do I need to know how to program computers? üôÉ",
    "text": "Do I need to know how to program computers? üôÉ\nIn short‚Ä¶ YES! But don‚Äôt be intimated by this, we will walk through the computer code in the workshop together, trying to understand it by functionality instead of blindly learning to type some letters on a screen.\nIn particular, bioinformatics has historically revolved around the use of computer terminals (or command-line, CLI), using a terminal basically feels like looking inside the void soul of your computer, a spot of complete darkness, just like you imagine it.\n\n‚ò†Ô∏è If you dare, you can look into the void by typing ‚åò+Space and typing ‚ÄúTerminal‚Äù on Mac or Win+R -> type ‚Äúcmd‚Äù -> press Enter on Windows!\n\nMost data-intensive operations in bioinformatics are handled by specialized ‚Äútools‚Äù (computer programs) that work in this environment, where we need to tell explicitly the computer what to do instead of pushing flashy buttons on the screen, something a bit different than what we are normally used to. This is because your computer‚Äôs Operating System is designed to make its use an actually enjoyable experience for you, but deep down everything ends in the void.\n\n\n\nIn this workshop we are not going to look at the computer‚Äôs terminal archaic way of communicating, we are instead going to instruct our computer on what we want to do by using a more modern and comprehensible language known as R."
  }
]